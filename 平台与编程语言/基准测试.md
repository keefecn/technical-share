| 序号 | 修改时间  | 修改内容           | 修改人 | 审稿人 |
| ---- | --------- | ------------------ | ------ | ------ |
| 1    | 2020-5-17 | 创建               | Keefe |  |
|      |           |                    |        |        |





---

[TOC]

---




#   1 基准测试简介

基准测试是指通过设计科学的测试方法、测试工具和测试系统，实现对一类测试对象的某项性能指标进行定量的和可对比的测试。

示例：

* CPU： 对计算机CPU进行[浮点运算](https://baike.baidu.com/item/浮点运算)、数据访问的带宽和延迟等指标的基准测试，可以使用户清楚地了解每一款CPU的运算性能及作业吞吐能力是否满足应用程序的要求；
* DB： 数据库管理系统的ACID（Atomicity, Consistency, Isolation, Durability, 原子性、一致性、独立性和持久性）、查询时间和联机事务处理能力等方面的性能指标进行基准测试，也有助于使用者挑选最符合自己需求的数据库系统。如经典的TPC基准测试。



可测量、可重复、可对比是基准测试的三大原则

* 可测量：是指测试的输入和输出之间是可达的，也就是测试过程是可以实现的，并且测试的结果可以量化表现
* 可重复：是指按照测试过程实现的结果是相同的或处于可接受的置信区间之内，而不受测试的时间、地点和执行者的影响；
* 可对比：是指一类测试对象的测试结果具有线性关系，测试结果的大小直接决定性能的高低。



##  测试方法



## 测试工具

### YCSB

YCSB是Yahoo开发的一个专门用来对新一代数据库进行基准测试的工具。全名是Yahoo! Cloud Serving Benchmar。上图是YCSB的结构，可以看成是一个数据库客户端。暗色的模块是可以替换的，Workload Executor是产生应用负载的，DB Interface Layer是将特定数据库的API转为YCSB的API，**用户可以自定义负载和数据库**。

YCSB的包括以下几大特性：

- 支持常见的数据库读写操作，如插入，修改，删除及读取；
- 多线程支持，YCSB用Java实现，有很好的多线程支持；
- 灵活定义场景文件，可以通过参数灵活的指定测试场景；
- 数据请求分布方式多样，支持随机、Zipfian以及其他请求分布方式；
- 可扩展性强，可通过扩展Workload的方式来修改或者扩展YCSB的功能。

（2）测试流程

①建立测试数据库database；

②在数据库中建立结构相同的3个测试集合（Test_20、Test_80、Test_300）；

③利用YCSB的S1场景向测试集合中分别插入一定数量的文档（500万、3000万、1亿）；

④利用YCSB的S2~S5场景分别在3个测试集合上进行多线程测试；

⑤结果数据的分析。

（3）测试场景

| 场景名 | 场景介绍                        | 场景配置                                |
| :----- | :------------------------------ | :-------------------------------------- |
| S1     | 插入（100% insert）             | insertproportion=1                      |
| S2     | 多读少写（90% read/10% update） | readproportion=0.9 updateproportion=0.1 |
| S3     | 读写均衡（50% read/50% update） | readproportion=0.5 updateproportion=0.5 |
| S4     | 多写少读（10% read/90% update） | readproportion=0.1 updateproportion=0.9 |
| S5     | 只读 （100% read）              | readproportion=1                        |

（4）测试表结构

| 集合名   | 大小  | 文档数 |
| -------- | ----- | ------ |
| Test_20  | 20GB  | 500万  |
| Test_80  | 80GB  | 3000万 |
| Test_200 | 300GB | 1亿    |

备注： 每个文档大小是2KB~5KB；索引_id



## 本章参考



# 2 基础算法 

算法复杂度衡量 参见  [算法分析和设计](算法分析和设计.md)

## C++排序算法 

数据准备：构建三组数据，分别是顺序、降序和随机数据。

测试函数：C++ 的排序函数如 QuickSort

```c++
#include <iostream>
#include <iomanip>
#include <stdlib.h>
#include <time.h>
#include <math.h>

#include "sort.h"

using namespace std;

#define random(num) (rand() % (num))
#define randomize() srand((unsigned)time(NULL))
#define N 10000 //排序元素的数目
#define SORT QuickSort //排序方法，可变

class timer//单位ms
{
public:
    void start()
    {
        start_t = clock();
    }
    clock_t time()
    {
        return (clock() - start_t);
    }
private:
    clock_t start_t;
};

int KCN, RMN;
timer TIMER;

//KCN: 用来计算与key值比较次数，RMN用来计算移动次数
void test(int a[])
{
    TIMER.start();
    SORT<int>(a, N, KCN, RMN);
    cout << "\tTimeSpared: " << TIMER.time() << "ms" << endl;
    cout << "KCN=" << left << setw(11) << KCN;
    cout << "KCN/N=" << left << setw(11)<< (double)KCN/N;
    cout << "KCN/N^2=" << left << setw(11)<< (double)KCN/N/N;
    cout << "KCN/NlogN=" << left << setw(11)<< (double)KCN/N/log((double)N)*log(2.0) << endl;
    cout << "RMN=" << left << setw(11) << RMN;
    cout << "RMN/N=" << left << setw(11)<< (double)RMN/N;
    cout << "RMN/N^2=" << left << setw(11)<< (double)RMN/N/N;
    cout << "RMN/NlogN=" << left << setw(11)<< (double)RMN/N/log((double)N)*log(2.0) << endl;
    cout <<  endl;
}



int main()
{
    int i;
    //randomize();为了在相同情况下比较各个排序算法，不加这句
    int* ascending = new int[N]; //升序序列
    int* descending = new int[N]; //降序序列
    int* randomness = new int[N]; //随机序列
    for (i = 0; i < N; i++)
    {
        ascending[i] = i;
        randomness[i] = i;
        descending[i] = N - i - 1;
    }
    for (i = 0; i < N; i++) swap(randomness[i], randomness[random(N)]);
    cout << "Sort ascending N=" << N;
    test(ascending);
    cout << "Sort randomness N=" << N;
    test(randomness);
    cout << "Sort descending N=" << N;
    test(descending);
    return 0;
}
```





## python排序算法 

测试设计

* 数据准备：随机N个序列
* 测试函数: bisect.insort_left  list.sort()  heapq.heappush

测试代码

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @author keefe
# @date 2017/9/16
# @see https://segmentfault.com/q/1010000000664272

import time
import bisect
import heapq
import random

def sort1(n):
    """
    bisect 插入排序
    算法复杂度：  O(n^2)
    :param n:
    :return:
    """
    lst = []
    for i in range(n):
        bisect.insort_left(lst, random.randint(1, 10000))
    return lst


def sort2(n):
    """ 
    lst.sort 列表排序
    算法复杂度：  O(nlogn)
    @see http://svn.python.org/projects/python/trunk/Objects/listsort.txt
    """
    lst = []
    for i in range(n):
        lst.append(random.randint(1, 10000))
    lst.sort()
    return lst


def sort3(n):
    """
    堆排序  heapq:
    算法复杂度：  O(nlogn)
    :param n:
    :return:
    """
    lst = []
    for i in range(n):
        heapq.heappush(lst, random.randint(1, 10000))
    return lst


def sort4(n):
    """ sort4: for test"""


def test_sort():
    for func in [sort1, sort2, sort3, sort4]:
        time1 = time.clock()
        func(100000)
        time2 = time.clock()
        time_all = time2 - time1
        # print(func.__doc__, time_all)
        print(func.__name__, time_all)


if __name__ == "__main__":
    test_sort()
```





#  3 并发能力

## 2.1 python并发

python并发主要有多进程multiprocessing、多线程thread。
并发机制包括socket、[asynchat](https://docs.python.org/2/library/asynchat.html#module-asynchat)、 [asyncore](https://docs.python.org/2/library/asyncore.html#module-asyncore)(select)。
**应用场景：**

* cpu密集型: line>多进程>多线程；
* io密集型：多进程>line>多线程
* http密集型：多线程>多进程>line，推荐多线程。


**结论**：1. 在单核情况下，串行有应用场景。在多核情况下，一般不考虑串行。

2. 综合场景下，多进程是上述最优选择；但在网络请求场景下（如多线程下载多文件），首选多线程。
3. 大批量写数据库的同一张表，用串行比多线程或多进程写更高效。因为数据库写表要上锁。



测试设计

* 数据准备：三类型函数 cpu（只涉及计算）、io（read+write文件）、http（网络访问）
* 并发函数：多进程、多线程

测试代码如下

```python
#! /usr/bin/env python
# coding=utf-8
"""
-------------------------------------------------
File Name：     performance_test.py
Description :
Author :       Keefe Wu
date：         2017/1/17
refer:  http://python.jobbole.com/86822/
conclusion: cpu/io/http各种密集型的性能比较（按使用时间升序排）
    cpu密集型: line>多进程>多线程；
    io密集型：多进程>line>多线程
    http密集型：多线程>多进程>line，推荐多线程。
结论：综合场景下，多进程是上述最优选择；但在网络请求场景下，首选多线程。
备注：进程/线程创建需要时间，因此测试时长最好在一分钟以上
-------------------------------------------------
"""
import time
import requests

from threading import Thread
from multiprocessing import Process

REPEAT_NUM = 10  # 重复次数/线程数/进程数


def count_with_args(x, y):
    # 定义CPU密集的计算函数: 5万*3=15万次
    c = 0
    while c < 50000:
        c += 1
        x += x
        y += y


def write():
    # 定义IO密集的文件读写函数：50万行
    f = open("test.txt", "w")
    for x in range(500000):
        f.write("testwrite\n")
    f.close()


def read():
    f = open("test.txt", "r")
    lines = f.readlines()
    f.close()


# 不带参数的测试函数：count/io/http_request
def count():
    # count_with_args(1, 1)
    c = 0
    while c < 50000:
        c += 1

def io():
    write()
    read()

def http_request():
    # 定义网络请求函数
    _head = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36'}
    url = "http://www.tieba.com"
    try:
        webPage = requests.get(url, headers=_head)
        html = webPage.text
        return {"context": html}
    except Exception as e:
        return {"error": e}


def line_test_more():
    """ 测试线性执行三种操作所需时间 """
    # CPU密集操作
    t = time.time()
    for x in range(REPEAT_NUM):
        count()
    print("Line cpu", time.time() - t)

    # IO密集操作
    t = time.time()
    for x in range(REPEAT_NUM):
        io()
    print("Line IO", time.time() - t)

    # 网络请求密集型操作
    t = time.time()
    for x in range(REPEAT_NUM):
        http_request()
    print("Line Http Request", time.time() - t)


def multithread_cpu_test():
    # 测试多线程并发执行CPU密集操作所需时间
    counts = []
    t = time.time()
    for x in range(REPEAT_NUM):
        thread = Thread(target=count_with_args, args=(1, 1))
        counts.append(thread)
        thread.start()

    e = counts.__len__()
    while True:
        for th in counts:
            if not th.is_alive():
                e -= 1
        if e <= 0:
            break
    print("multithread", time.time() - t)


def line_test(func):
    # 线性执行，参数为函数名
    t = time.time()
    for x in range(REPEAT_NUM):
        func()
    print("line", func.__name__, time.time() - t)


def multithread_test(func):
    # 多线程并发，参数为函数名
    t = time.time()
    tasks = []
    t = time.time()
    for x in range(REPEAT_NUM):
        thread = Thread(target=func)
        tasks.append(thread)
        thread.start()

    e = tasks.__len__()
    while True:
        for th in tasks:
            if not th.is_alive():
                e -= 1
        if e <= 0:
            break
    print("multithread", func.__name__, time.time() - t)


def multiprocess_test(func):
    # 多进程并发，参数为函数名
    tasks = []
    t = time.time()
    for x in range(REPEAT_NUM):
        process = Process(target=func)
        tasks.append(process)
        process.start()
    e = tasks.__len__()
    while True:
        for th in tasks:
            if not th.is_alive():
                e -= 1
        if e <= 0:
            break
    print("multiprocess", func.__name__, time.time() - t)


def line_compare(type=0):
    if type == 1:
        line_test(count)
    elif type == 2:
        line_test(io)
    elif type == 3:
        line_test(http_request)
    else:
        line_test(count)
        line_test(io)
        line_test(http_request)


def multithread_compare(type=0):
    if type == 1:
        multithread_test(count)
    elif type == 2:
        multithread_test(io)
    elif type == 3:
        multithread_test(http_request)
    else:
        multithread_test(count)
        multithread_test(io)
        multithread_test(http_request)


def multiprocess_compare(type=0):
    if type == 1:
        multiprocess_test(count)
    elif type == 2:
        multiprocess_test(io)
    elif type == 3:
        multiprocess_test(http_request)
    else:
        multiprocess_test(count)
        multiprocess_test(io)
        multiprocess_test(http_request)


if __name__ == '__main__':
    # line_test()
    type = 1  # 1~cpu, 2~io, 3~net, 4~all
    funcs = [line_compare, multithread_compare, multiprocess_compare]
    for func in funcs:
        func(type)
```

输出

```shell
line count 0.043030738830566406
multithread count 0.04502987861633301
multiprocess count 2.7479522228240967
```





## 本章参考



# 4 DB性能 (CRUD)

DB-ENGINES排名（按市场欢迎程度 ）：https://db-engines.com/en/

##  DB性能测试结论

DB性能比较先得到定量数据，继而推出定性结论。



### 定量比较

测试设备：个人PC机~ Windowns 8.1  (4U8G，Intel i5-4210U @1.7GHZ)



表格 1 DB定量比较表

| DB            | CREATE | READ  | UPDATE | DELETE | 并发数 | 版本    |
| ------------- | ------ | ----- | ------ | ------ | ------ | ------- |
| MySQL  MyISAM |        | 16233 |        |        |        |         |
| MySQL  InnoDB |        |       |        |        |        |         |
| MongoDB       | 9000   | 15000 |        |        |        | 4.0.3   |
| Redis         | 15288  | 24721 |        |        |        | 3.2.100 |
| Memcached     |        |       |        |        |        |         |
|               |        |       |        |        |        |         |

备注： 测试时间是2020-5-17，单位是QPS~每秒处理的请求数。DB都是单机版本 standalone。以上CRUD还可组合场景即只读、读多写少、读写混合、读少写多。

1. Redis：只比较string类型，使用Redis官方性能测试工具redis-benchmark。
2. MongoDB:  



### 定性比较

表格 2 DB定性比较表

| DB            | 优点             | 缺点 | 建议应用场景         |
| ------------- | ---------------- | ---- | -------------------- |
| MySQL  MyISAM | OLAP，在线查询。 |      | 结构化数据，关联查询 |
| MySQL  InnoDB | ACID，支持事务。 |      |                      |
| MongoDB       |                  |      |                      |
| Redis         |                  |      |                      |
| memcached     |                  |      |                      |





## Redis 

官方性能测试工具： redis-benchmark

```shell
$E:\dev\db\Redis>redis-server.exe --version
Redis server v=3.2.100 sha=00000000:0 malloc=jemalloc-3.6.0 bits=64 build=dd26f1
f93c5130ee

$redis-benchmark -n 100000 -q
# 输出
PING_INLINE: 25000.00 requests per second
PING_BULK: 26392.19 requests per second
SET: 15288.18 requests per second
GET: 24721.88 requests per second
INCR: 16371.97 requests per second
LPUSH: 16883.34 requests per second
RPUSH: 18238.19 requests per second
LPOP: 19109.50 requests per second
RPOP: 18674.14 requests per second
SADD: 21612.28 requests per second
SPOP: 24630.54 requests per second
LPUSH (needed to benchmark LRANGE): 16669.45 requests per second
LRANGE_100 (first 100 elements): 9016.32 requests per second
LRANGE_300 (first 300 elements): 4960.56 requests per second
LRANGE_500 (first 450 elements): 4200.45 requests per second
LRANGE_600 (first 600 elements): 3451.37 requests per second
MSET (10 keys): 9294.54 requests per second
```



## MongoDB

测试工具：YCSB（Yahoo! Cloud Serving Benchmar，Yahoo开发的一个专门用来对新一代数据库进行基准测试的工具）

数据准备： 单集合里插入100000篇文档，集合collection名是performance_log

插入测试 insert/insert_many

```shell
# 单行插入
for(i=0;i<10000;i++){          db.performance_log.insert({"uid":i,"name":"mongodb","age":6,"date":new Date()});
}

# 批量插入
```



查找测试 find/find_one/skip

 ```sql
# 下面示例: 集合名~follower,查询条件~filter
# 单行读取
db.follower.find({'user_id':1000069, 'follower_id': 1000089}).Limit(1)

# 分页读取1:  随着查询偏移量的上升(1w, 5w, 10w)，查询耗时出现线性增长。尽量避免使用 Skip 做为分页策略
db.getcollection("follower").Find(filter).Sort("-_id").Skip(10000).Limit(10).All()

# 分页读取2：大数据分页，排序字段_id也可以用其它排序字段
def get_page_data(page_no, pagesize, id):
  if page_no == 0:
     res = db.follower.find(filter).limit(pagesize)
  else:
     filter.update( { "_id" {"$lt" : id } } ) 
     res = db.follower.find(filter).sort("_id"， -1).limit(pagesize)
  id = res[len(res)-1].get("_id")
  return res, id
 ```



测试结论

- MongoDB读写比较：读性能优于写性能（吞吐率、稳定性）；写操作对整体吞吐率的影响，随着数据量的增加而越发明显。
- MongoDB集合数据量：集合可以达到千万~100亿级别。单个集合达到亿级数据量时，MongoDB的读写性能均有明显下降，设计集合时，应尽量将集合的文档数量控制在亿级以下。
- MongoDB大数据分页：limit数量主要取决于结果集所要占用的内存，分页大小10万是个比较理想的值。分页办法主要二种：（1）skip，跳过分页。记录集超过百万，skip会出现严重的性能问题。（2）排序分页，ObjectID(_id) 或者索引子段排序（缺省降序-1，如果改变排序方式，查询速度有所降低），获取上一次排序的头或尾值，查询条件用 `$gt`或 `$lt` 排序字段。 
- 并发调优：MongoDB在TS90上的针对中小数据量的读写，以128线程为最优，对于大数据量的读写，以64线程为最优；
- 索引：_id是缺省索引。尽可能不建索引，数据量越大，索引增长得越快，占用内存越多，插入也越慢。



## MySQL

主要测试二个引擎 MyISAM 和 InnoDB





## Memcache 压力测试

测试代码如下

```perl
#!/usr/bin/perl
# file: stress_memcache.pl

use strict;
use lib '../../api/perl/lib';
use Cache::Memcached;
use Time::HiRes qw(time);

unless (@ARGV == 2) {
    die "Usage: stress-memcached.pl ip:port threads\n";
}

my $host = shift;
my $threads = shift;

my $memc = new Cache::Memcached;
$memc->set_servers([$host]);

unless ($memc->set("foo", "bar") &&
        $memc->get("foo") eq "bar") {
    die "memcached not running at $host ?\n";
}
$memc->disconnect_all();


my $running = 0;
while (1) {
    if ($running < $threads) {
        my $cpid = fork();
        if ($cpid) {
            $running++;
            #print "Launched $cpid.  Running $running threads.\n";
        } else {
            stress();
            exit 0;
        }
    } else {
        wait();
        $running--;
    }
}

sub stress {
    undef $memc;
    $memc = new Cache::Memcached;
    $memc->set_servers([$host]);

    my ($t1, $t2);
    my $start = sub { $t1 = time(); };
    my $stop = sub {
        my $op = shift;
        $t2 = time();
        my $td = sprintf("%0.3f", $t2 - $t1);
        if ($td > 0.25) { print "Took $td seconds for: $op\n"; }
    };

    my $max = rand(50);
    my $sets = 0;

    for (my $i = 0; $i < $max; $i++) {
        my $key = key($i);
        my $set = $memc->set($key, $key);
        $sets++ if $set;
    }

    for (1..int(rand(500))) {
        my $rand = int(rand($max));
        my $key = key($rand);
        my $meth = int(rand(3));
        my $exp = int(rand(3));
        undef $exp unless $exp;
        $start->();
        if ($meth == 0) {
            $memc->add($key, $key, $exp);
            $stop->("add");
        } elsif ($meth == 1) {
            $memc->delete($key);
            $stop->("delete");
        } else {
            $memc->set($key, $key, $exp);
            $stop->("set");
        }
        $rand = int(rand($max));
        $key = key($rand);
        $start->();
        my $v = $memc->get($key);
        $stop->("get");
        if ($v && $v ne $key) { die "Bogus: $v for key $rand\n"; }
    }

    $start->();
    my $multi = $memc->get_multi(map { key(int(rand($max))) } (1..$max));
    $stop->("get_multi");
}

sub key {
    my $n = shift;
    $_ = sprintf("%04d", $n);
    if ($n % 2) { $_ .= "a"x20; }
    $_;
}

```



# 5 WEB框架性能

参见 https://www.techempower.com/benchmarks/

代码库： [Source Code and Requirements](https://github.com/TechEmpower/FrameworkBenchmarks/wiki/Project-Information-Framework-Tests-Overview)  https://github.com/TechEmpower/FrameworkBenchmarks

测试方法：十几种编程语言，几百个框架，使用不同数据库（MYSQL/Postgres/Mongodb），不同的请求方法（单个请求、多并发请求），按响应时间排序。



## 本章参考





# 参考资料

[1].   IPC-H http://www.tpc.org/tpch/ 

[2].  数据库评测报告第二期：MongoDB-3.2 https://cloud.tencent.com/developer/article/1005453 